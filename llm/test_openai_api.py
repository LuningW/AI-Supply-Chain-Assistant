import openai
import json
from dispatch_response_prompt import ask_supply_chain_assistant_final

# è®¾ç½® API å¯†é’¥
client = openai.OpenAI(api_key="")  # ğŸ” æ›¿æ¢ä¸ºä½ çš„ key

if __name__ == "__main__":
    # åˆå§‹åŒ–å¯¹è¯å†å²ä¸ºç©º
    history = []

    # è¾“å…¥é—®é¢˜ï¼ˆä½ å¯ä»¥æ¢æˆå…¶å®ƒé—®é¢˜æµ‹è¯•ï¼‰
    question = "Why does warehouse w2 receive more shipments than w1?"

    # è°ƒç”¨ä¸»æµç¨‹
    intent, response, history = ask_supply_chain_assistant_final(question, history)

    # è¾“å‡ºç»“æœ
    print("ğŸ” åˆ†ç±»ç»“æœï¼ˆIntent Typeï¼‰:", intent)
    print("\nğŸ§  GPT å›å¤å†…å®¹ï¼š\n", response)

"""
# æµ‹è¯•dispatch prompt
# åŠ è½½ prompt é…ç½®
with open("llm/dispatch_prompt_updated.json", "r") as f:
    prompt_config = json.load(f)["dispatch_prompt"]

# ç”¨æˆ·è¾“å…¥
user_question = "What would happen if the demand at market c1 increased by 10%?"
inputs = {
    "{$QUESTION}": user_question,
    "{$previous_interactions}": "",
    "{$background}": "",
    "{$scenario_description}": ""
}

# æ„é€  prompt
prompt_text = (
    f"{prompt_config['role']}\n\n"
    f"{prompt_config['task_instruction']}\n\n"
    f"Instructions: {prompt_config['instructions']}\n\n"
)

for ex in prompt_config["examples"]:
    prompt_text += f"Question: {ex['User Question']}\n"
    prompt_text += f"Answer: {ex['Dispatch Response']}\n\n"

prompt_text += f"Question: {inputs['{$QUESTION}']}\n"
prompt_text += "Answer:"

# ä½¿ç”¨æ–°ç‰ˆ API å‘é€è¯·æ±‚
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": prompt_text}
    ],
    temperature=0
)

# æ‰“å°ç»“æœ
intent_type = response.choices[0].message.content.strip()
print("ğŸ” Detected intent type:", intent_type)
"""